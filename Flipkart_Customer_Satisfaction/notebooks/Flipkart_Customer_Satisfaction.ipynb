{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14ec19b",
   "metadata": {},
   "source": [
    "# Flipkart Customer Service Satisfaction — Classification Project\n",
    "\n",
    "**Dataset:** flipkart_customer_service.csv\n",
    "\n",
    "This notebook uses the real Flipkart dataset to build a classification model for predicting Customer Satisfaction (CSAT).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e6b500",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7fe77",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0294fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('flipkart_customer_service.csv')\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f87a3",
   "metadata": {},
   "source": [
    "## 3. Quick Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values per column:\\n', df.isnull().sum())\n",
    "print('\\nCSAT Score distribution:\\n', df['CSAT Score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645282c",
   "metadata": {},
   "source": [
    "## 4. Target Variable Transformation\n",
    "\n",
    "Convert CSAT Score (1–5) to binary classification:\n",
    "- **Satisfied (1)** = 4 or 5\n",
    "- **Dissatisfied (0)** = 1–3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e57203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['satisfaction'] = df['CSAT Score'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "print(df['satisfaction'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c59f1",
   "metadata": {},
   "source": [
    "## 5. Feature Selection & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with very high missing values\n",
    "cols_to_drop = ['Item_price','connected_handling_time','Customer_City','Product_category','order_date_time']\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Text column\n",
    "text_col = 'Customer Remarks'\n",
    "\n",
    "# Categorical columns\n",
    "cat_cols = ['channel_name','category','Sub-category','Agent_name','Supervisor','Manager','Tenure Bucket','Agent Shift']\n",
    "\n",
    "# Numeric columns (none significant in dataset after dropping, except we can add later if needed)\n",
    "numeric_cols = []\n",
    "\n",
    "print('Remaining columns:', df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af584262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features with LabelEncoder\n",
    "cat_encoded = pd.DataFrame()\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    cat_encoded[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Text feature: TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_text = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "\n",
    "# Combine features\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "X = hstack([csr_matrix(cat_encoded.values), X_text]).tocsr()\n",
    "y = df['satisfaction'].values\n",
    "\n",
    "print('Feature matrix shape:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac9213e",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502064bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa00ac7",
   "metadata": {},
   "source": [
    "## 7. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print('Logistic Regression Results:\\n', classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print('Random Forest Results:\\n', classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ecc55",
   "metadata": {},
   "source": [
    "## 8. Evaluation: ROC-AUC & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98338b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(lr, 'predict_proba'):\n",
    "    lr_probs = lr.predict_proba(X_test)[:,1]\n",
    "    print('Logistic Regression ROC-AUC:', roc_auc_score(y_test, lr_probs))\n",
    "if hasattr(rf, 'predict_proba'):\n",
    "    rf_probs = rf.predict_proba(X_test)[:,1]\n",
    "    print('Random Forest ROC-AUC:', roc_auc_score(y_test, rf_probs))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8ed01d",
   "metadata": {},
   "source": [
    "## 9. Feature Importance\n",
    "\n",
    "We check which categorical features & TF-IDF words are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Top words correlated with satisfaction\n",
    "X_text_arr = X_text.toarray()\n",
    "mean_pos = X_text_arr[y==1].mean(axis=0)\n",
    "mean_neg = X_text_arr[y==0].mean(axis=0)\n",
    "diff = mean_pos - mean_neg\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print('Top positive words:')\n",
    "for i in np.argsort(diff)[-10:][::-1]:\n",
    "    print(feature_names[i], diff[i])\n",
    "\n",
    "print('\\nTop negative words:')\n",
    "for i in np.argsort(diff)[:10]:\n",
    "    print(feature_names[i], diff[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50811d82",
   "metadata": {},
   "source": [
    "## 10. Recommendations & Next Steps\n",
    "\n",
    "- Focus on channels/categories with lower satisfaction.\n",
    "- Train agents with low performance (Agent_name-wise analysis possible).\n",
    "- Monitor common negative feedback words to flag at-risk tickets.\n",
    "- Deploy this model to support teams to proactively manage dissatisfaction.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
